{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bc9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('3y_GBT').getOrCreate()\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dda8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing processed data which has a header. Schema is automatically configured.\n",
    "df_join = spark.read.csv('Datasets/London_3y.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "624c4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_join.withColumn(\"lg_day_length\", log10(col(\"day_length\"))) \\\n",
    "                .withColumn(\"lg_windspeed\", log10(col(\"windspeed\"))) \\\n",
    "                .withColumn(\"reuse_rate\", col(\"count\")/16000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63dedb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+---------+------+-----------+---------+----------+------------------+------------------+----------+\n",
      "|      date|avg_duration|count|feelslike|precip|precipcover|windspeed|day_length|     lg_day_length|      lg_windspeed|reuse_rate|\n",
      "+----------+------------+-----+---------+------+-----------+---------+----------+------------------+------------------+----------+\n",
      "|2017-01-23|     817.726|23031|      0.6| 0.199|       8.33|      6.4|     8.721|0.9405662864900902|0.8061799739838872| 1.4394375|\n",
      "|2017-01-24|     851.122|26299|      3.3| 0.001|       4.17|     11.5|      8.77|0.9429995933660404|1.0606978403536116| 1.6436875|\n",
      "|2017-01-25|     832.233|24937|      0.0| 0.001|       4.17|     11.3|      8.82|0.9454685851318197|1.0530784434834197| 1.5585625|\n",
      "|2017-01-26|     803.408|23607|     -3.4|   0.0|        0.0|     13.0|     8.871|  0.94797257924578|1.1139433523068367| 1.4754375|\n",
      "|2017-01-27|      848.22|23138|      0.8|   0.0|        0.0|     17.1|     8.923|0.9505108929859966|1.2329961103921538|  1.446125|\n",
      "|2017-01-30|     840.027|24732|      6.3|   9.0|       4.17|     15.5|     9.084|0.9582771255476976|1.1903316981702914|   1.54575|\n",
      "|2017-01-31|     810.323|22383|      4.3| 0.601|       8.33|     17.9|     9.139|0.9608986773266607| 1.252853030979893| 1.3989375|\n",
      "|2017-02-01|     817.367|22870|     10.1|  7.99|       8.33|     23.7|     9.195|0.9635517335740963| 1.374748346010104|  1.429375|\n",
      "|2017-02-02|     829.222|25296|     10.8| 0.211|       12.5|     27.6|     9.251|0.9661886809561372|1.4409090820652177|     1.581|\n",
      "|2017-02-03|     862.866|22858|      6.9| 0.816|       12.5|     37.2|     9.308|0.9688563746146923|1.5705429398818975|  1.428625|\n",
      "|2017-02-06|     850.018|23964|      3.4|   0.0|        0.0|     17.3|     9.482|0.9768999509829378|1.2380461031287955|   1.49775|\n",
      "|2017-02-07|     855.484|26764|      6.4| 6.204|       8.33|     15.2|     9.542|0.9796394122229073|1.1818435879447726|   1.67275|\n",
      "|2017-02-08|      813.33|25384|      2.8|   0.0|        0.0|     13.6|     9.601|0.9823164696920653|1.1335389083702174|    1.5865|\n",
      "|2017-02-09|     792.414|22619|     -0.9|   0.0|        0.0|     17.3|     9.661|0.9850220821095351|1.2380461031287955| 1.4136875|\n",
      "|2017-02-10|     775.378|18459|     -1.4| 0.401|      16.67|     15.9|     9.722|0.9877556167385233|1.2013971243204515| 1.1536875|\n",
      "|2017-02-13|     889.814|23821|      2.4|   0.0|        0.0|     26.8|     9.906|0.9958983236464373| 1.428134794028789| 1.4888125|\n",
      "|2017-02-14|     906.504|26265|      5.5|   0.0|        0.0|     16.3|     9.968|0.9986080293150944| 1.212187604403958| 1.6415625|\n",
      "|2017-02-15|     856.048|24041|      8.4|  1.01|       4.17|     22.5|     10.03|1.0013009330204181|1.3521825181113625| 1.5025625|\n",
      "|2017-02-16|     902.886|26278|      7.5|   0.2|       8.33|     18.6|    10.093|1.0040202732532415|1.2695129442179163|  1.642375|\n",
      "|2017-02-17|     950.127|25359|      8.4| 0.199|       4.17|     15.6|    10.156|1.0067226922016845|1.1931245983544616| 1.5849375|\n",
      "+----------+------------+-----+---------+------+-----------+---------+----------+------------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260476e4",
   "metadata": {},
   "source": [
    "**GBT regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b9fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbea3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input columns are the feature column names, and the output column is what you'd like the new column to be named. \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"feelslike\", \"precip\", \"precipcover\",'lg_day_length','lg_windspeed'],\n",
    "    outputCol=\"features\")\n",
    "output = assembler.transform(df_join)\n",
    "all_data = output.select(\"features\",'reuse_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89c8afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|reuse_rate|\n",
      "+--------------------+----------+\n",
      "|[0.6,0.199,8.33,0...| 1.4394375|\n",
      "|[3.3,0.001,4.17,0...| 1.6436875|\n",
      "|[0.0,0.001,4.17,0...| 1.5585625|\n",
      "|[-3.4,0.0,0.0,0.9...| 1.4754375|\n",
      "|[0.8,0.0,0.0,0.95...|  1.446125|\n",
      "|[6.3,9.0,4.17,0.9...|   1.54575|\n",
      "|[4.3,0.601,8.33,0...| 1.3989375|\n",
      "|[10.1,7.99,8.33,0...|  1.429375|\n",
      "|[10.8,0.211,12.5,...|     1.581|\n",
      "|[6.9,0.816,12.5,0...|  1.428625|\n",
      "|[3.4,0.0,0.0,0.97...|   1.49775|\n",
      "|[6.4,6.204,8.33,0...|   1.67275|\n",
      "|[2.8,0.0,0.0,0.98...|    1.5865|\n",
      "|[-0.9,0.0,0.0,0.9...| 1.4136875|\n",
      "|[-1.4,0.401,16.67...| 1.1536875|\n",
      "|[2.4,0.0,0.0,0.99...| 1.4888125|\n",
      "|[5.5,0.0,0.0,0.99...| 1.6415625|\n",
      "|[8.4,1.01,4.17,1....| 1.5025625|\n",
      "|[7.5,0.2,8.33,1.0...|  1.642375|\n",
      "|[8.4,0.199,4.17,1...| 1.5849375|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0175c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "058f0d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|         reuse_rate|\n",
      "+-------+-------------------+\n",
      "|  count|                577|\n",
      "|   mean|  1.937683817157713|\n",
      "| stddev|0.42791477130391914|\n",
      "|    min|          0.3890625|\n",
      "|    max|          2.8114375|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|        reuse_rate|\n",
      "+-------+------------------+\n",
      "|  count|               137|\n",
      "|   mean|1.9831500912408766|\n",
      "| stddev|0.4189698680944552|\n",
      "|    min|         0.4859375|\n",
      "|    max|          2.815375|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# randomised split 80/20, \n",
    "train_data,test_data = all_data.randomSplit([0.8,0.2])\n",
    "# check data\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb4edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GBT model\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol='reuse_rate', seed=42)\n",
    "\n",
    "#Train the model\n",
    "gbtModel = gbt.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d82ba851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20\n",
      "MAE: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions = gbtModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse_eval = RegressionEvaluator(labelCol='reuse_rate', metricName='rmse')\n",
    "mae_eval = RegressionEvaluator(labelCol='reuse_rate', metricName='mae')\n",
    "\n",
    "rmse = rmse_eval.evaluate(predictions)\n",
    "mae = mae_eval.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"RMSE: {:.2f}\".format(rmse))\n",
    "print(\"MAE: {:.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aa13c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|            features|reuse_rate|        prediction|\n",
      "+--------------------+----------+------------------+\n",
      "|[-3.2,0.605,8.33,...|   1.26225|1.5808476229678567|\n",
      "|[-2.6,6.38,16.67,...|  0.794375| 1.405889499265029|\n",
      "|[-1.9,0.199,4.17,...|   1.44975|1.4629250287033624|\n",
      "|[-1.3,0.0,0.0,0.9...| 1.5033125|1.4954840198405017|\n",
      "|[-1.1,0.0,0.0,1.0...| 1.4120625| 1.394880881621903|\n",
      "|[-0.9,0.0,0.0,0.9...| 1.4136875|1.5161508976800702|\n",
      "|[-0.3,0.0,0.0,0.9...|   1.59775| 1.472921068803218|\n",
      "|[-0.3,0.0,0.0,0.9...|  1.515375|1.4580459388465605|\n",
      "|[-0.2,1.995,12.5,...| 1.5729375| 1.444946460142404|\n",
      "|[1.0,0.796,8.33,0...| 1.5058125|1.3278126445019733|\n",
      "|[2.2,0.199,4.17,0...| 1.7339375|1.6185928898117032|\n",
      "|[2.8,0.0,0.0,0.98...|    1.5865|1.6145273001827798|\n",
      "|[3.1,3.997,8.33,0...| 1.6931875| 1.443325872088565|\n",
      "|[3.1,5.006,16.67,...| 1.2370625|1.4157654429894178|\n",
      "|[3.2,1.996,4.17,0...|   1.69125|1.3454466583566262|\n",
      "|[3.3,0.001,4.17,0...|  1.814875|1.6218080739224132|\n",
      "|[3.4,0.805,4.17,1...|  1.575375|   1.6190687626205|\n",
      "|[4.0,6.807,12.5,1...|     1.639|1.6148499417535338|\n",
      "|[4.1,11.387,8.33,...|  0.972875|0.4637924898303296|\n",
      "|[4.2,0.005,4.17,0...| 1.7654375|1.7153621509088894|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "309949df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a735e3b",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2e84",
   "metadata": {},
   "source": [
    "In Gradient Boosting, the main hyperparameters are the number of trees, the learning rate, and the maximum depth of each tree. We can use cross-validation and grid search to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b766ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2, 4, 6]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 50, 100]) \\\n",
    "    .addGrid(gbt.stepSize, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol='reuse_rate', metricName='rmse')\n",
    "\n",
    "# Define the cross-validator\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5, seed=42)\n",
    "\n",
    "# Train the model using cross-validation\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "cv_predictions = cv_model.transform(test_data)\n",
    "\n",
    "cv_rmse = evaluator.evaluate(cv_predictions)\n",
    "print(\"CV RMSE: {:.2f}\".format(cv_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1281e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAE: 0.15\n"
     ]
    }
   ],
   "source": [
    "cv_mae = mae_eval.evaluate(cv_predictions)\n",
    "print(\"CV MAE: {:.2f}\".format(cv_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c892a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|count|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[-3.4,0.0,0.0,0.9...|23607| 23410.06621950035|\n",
      "|[-1.6,0.0,0.0,0.9...|25600|22309.128984633393|\n",
      "|[-1.1,0.0,0.0,1.0...|22593|19447.933487223792|\n",
      "|[0.0,0.001,4.17,0...|24937|25755.448353089992|\n",
      "|[0.8,0.002,4.17,1...|25686|24400.436385610596|\n",
      "|[1.5,5.984,8.33,0...|20721|22541.583977819195|\n",
      "|[1.8,0.0,0.0,0.89...|23763|26542.366886791933|\n",
      "|[2.8,0.0,0.0,0.98...|25384| 27521.75800419014|\n",
      "|[2.9,0.0,0.0,0.93...|28392| 27455.81374323029|\n",
      "|[2.9,6.013,8.33,0...|19501|22161.254822247927|\n",
      "|[3.4,2.401,8.33,0...|23812| 22279.15576935453|\n",
      "|[3.6,1.0,8.33,1.1...|28083|23425.577601192206|\n",
      "|[3.8,0.0,0.0,1.02...|26383| 28157.80480433735|\n",
      "|[3.8,0.051,4.17,0...|29152|27196.161209085585|\n",
      "|[4.2,0.202,4.17,0...|17772| 26364.18870716653|\n",
      "|[4.6,0.8,8.33,0.9...|26776|21934.347327636067|\n",
      "|[4.6,0.804,8.33,1...|26775| 23026.56925040686|\n",
      "|[4.9,0.199,4.17,0...|25362|26550.408719234227|\n",
      "|[5.0,0.597,4.17,0...|28207| 27911.55420467866|\n",
      "|[5.4,0.2,4.17,0.9...|30193|26842.250365975764|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "719f490b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feelslike 0.4033\n",
      "precip 0.2416\n",
      "precipcover 0.0529\n",
      "lg_day_length 0.1623\n",
      "lg_windspeed 0.1398\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance scores\n",
    "importances = gbtModel.featureImportances\n",
    "\n",
    "# Create a list of feature names\n",
    "features = [\"feelslike\", \"precip\", \"precipcover\",'lg_day_length','lg_windspeed']\n",
    "\n",
    "# Print the feature importance scores\n",
    "for feature, importance in zip(features, importances):\n",
    "    print(feature, \"{:.4f}\".format(importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74317f9b",
   "metadata": {},
   "source": [
    "# step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17a7b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_akl = spark.read.csv('Datasets/Auckland_weather.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ad888f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_akl = df_akl.withColumn(\"lg_day_length\", log10(col(\"day_length\"))) \\\n",
    "                .withColumn(\"lg_windspeed\", log10(col(\"windspeed\")))\n",
    "akl_data = assembler.transform(df_akl).select(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c34e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[19.9,0.0,0.0,1.1...|2.2462594796465902|\n",
      "|[21.7,0.0,0.0,1.1...|2.3676553698113074|\n",
      "|[21.0,0.0,0.0,1.1...| 2.385366416668374|\n",
      "|[22.2,0.0,0.0,1.1...|2.4118573012833533|\n",
      "|[21.2,0.008,4.17,...| 2.334764741124993|\n",
      "|[21.5,0.0,0.0,1.1...|2.3676553698113074|\n",
      "|[21.0,0.116,12.5,...|2.2446821026870216|\n",
      "|[21.4,0.025,8.33,...| 2.168558368074246|\n",
      "|[22.2,0.0,0.0,1.1...|2.2467896566980707|\n",
      "|[22.2,0.0,0.0,1.1...|2.3628263485947874|\n",
      "|[22.4,0.0,0.0,1.1...|2.3186244171227415|\n",
      "|[21.6,0.616,8.33,...|2.0084027611228725|\n",
      "|[21.5,0.0,0.0,1.1...|2.1910802755355094|\n",
      "|[20.2,0.041,8.33,...|2.3672699320101174|\n",
      "|[20.6,0.108,12.5,...|2.3672699320101174|\n",
      "|[20.5,0.0,0.0,1.1...|2.2529379081205856|\n",
      "|[20.5,0.0,0.0,1.1...|2.1972285269580243|\n",
      "|[21.5,0.0,0.0,1.1...|2.3186244171227415|\n",
      "|[21.9,0.0,0.0,1.1...|2.3186244171227415|\n",
      "|[20.0,0.192,4.17,...|2.3605558461823337|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the re_use value for Auckland weather condition data\n",
    "akl_predict = cv_model.transform(akl_data)\n",
    "akl_predict.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7fd1aadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>Auckland</th>\n",
       "      <th>London</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.978110427860641</td>\n",
       "      <td>1.9464077380952374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stddev</td>\n",
       "      <td>0.2706933482941951</td>\n",
       "      <td>0.4262983491379373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min</td>\n",
       "      <td>1.3563069523671416</td>\n",
       "      <td>0.3890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max</td>\n",
       "      <td>2.4734609160919554</td>\n",
       "      <td>2.815375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary            Auckland              London\n",
       "0    mean   1.978110427860641  1.9464077380952374\n",
       "1  stddev  0.2706933482941951  0.4262983491379373\n",
       "2     min  1.3563069523671416           0.3890625\n",
       "3     max  2.4734609160919554            2.815375"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_AKL_stat = akl_predict.describe()\n",
    "df_LND_stat = all_data.describe()\n",
    "df_LND_stat = df_LND_stat.withColumnRenamed(\"summary\", \"sum\")\n",
    "df_compare = df_AKL_stat.join(df_LND_stat,df_AKL_stat[\"summary\"] == df_LND_stat[\"sum\"], how=\"inner\" )\n",
    "df_compare = df_compare.drop(\"sum\").where(df_compare[\"Summary\"] != 'count')\n",
    "#df_compare.drop(index='count').rename(columns={'prediction': 'Auckland', 'reuse_rate': 'London'}).boxplot()\n",
    "df_compare = df_compare.withColumnRenamed(\"prediction\", \"Auckland\").withColumnRenamed(\"reuse_rate\", \"London\")\n",
    "df_compare.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
